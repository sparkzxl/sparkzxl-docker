input {
  kafka {
    codec => "json"
    topics_pattern => "sparksys.*"
    bootstrap_servers => "192.168.3.5:9092"
    auto_offset_reset => "latest"
    consumer_threads => 2
    group_id => "logstash-g1"
  }
}
filter {
  mutate {
        gsub => ["message", "\\x", "\\\x"]
  }
  geoip {
        source => "message"
    }
  json {
    source => "message"
  }
}
output {
  elasticsearch {
    hosts => "es:9200"
    index => "filebeat_%{[fields][log_source]}-%{+YYYY.MM.dd}"
  }
}
